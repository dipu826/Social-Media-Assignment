{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39ae647e",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"title\": \"Elon Musk and Mark Zuckerberg&#39;s INSANE NEW Deal with Facebook!\",\n",
      "        \"description\": \"In a world where technology shapes our daily lives, two of the most influential names in the industry are joining forces. Elon Musk ...\",\n",
      "        \"videoId\": \"tj1ax525H_g\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"I Saw Elon Musk Driving a Cyber Truck!! #Shorts\",\n",
      "        \"description\": \"\",\n",
      "        \"videoId\": \"vrs5mx8Z3W4\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Elon Musk, why are you still working? You are worth $184B\",\n",
      "        \"description\": \"Check out the whole interview here. Our Interview with Elon Musk ...\",\n",
      "        \"videoId\": \"P7iRUw3Imw4\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Putin flirts, Putin sigma rule, Putin body language #sigma #confidence #bodylanguage #putin #shorts\",\n",
      "        \"description\": \"Putin flirts, Putin sigma rule, Putin body language #sigma #confidence #bodylanguage #putin #shorts power. authority.\",\n",
      "        \"videoId\": \"xG1zuIXC9dc\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Mark Zuckerberg on Threads, Elon Musk, AI, the Quest 3, and more\",\n",
      "        \"description\": \"In a rare interview, Meta CEO Mark Zuckerberg joined The Verge's deputy editor, Alex Heath, to discuss where AI is going next, ...\",\n",
      "        \"videoId\": \"9aCg7jH4S1w\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Do androids believe in God? Watch our interview with Ameca, a humanoid #robot at   #CES2022 #Shorts\",\n",
      "        \"description\": \"\",\n",
      "        \"videoId\": \"OASTvqNGspE\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Why Tom Holland Quit \\u274c\\ufe0fSocial Media\\ud83d\\udcf1\",\n",
      "        \"description\": \"As we all know, Tom Holland has become a household name for his incredible portrayal of Spider-Man in the Marvel Cinematic ...\",\n",
      "        \"videoId\": \"FtM5GI6JmWM\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"This can happen in Thailand\",\n",
      "        \"description\": \"\",\n",
      "        \"videoId\": \"BnWGNHx4XUI\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Bro\\u2019s hacking life \\ud83d\\ude2d\\ud83e\\udd23\",\n",
      "        \"description\": \"Bro got it all figured out NBA X CREATOR MERCH DROP   Flight, KOT4Q, Faze Rug, and Noah Beck created their own ...\",\n",
      "        \"videoId\": \"Aw0PL7MdcRo\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"19. Threads, Musk vs. Zuck and Supercloud 3\",\n",
      "        \"description\": \"On this week's episode of theCUBE Pod, industry analysts John Furrier and Dave Vellante discuss Meta's launch of Threads, the ...\",\n",
      "        \"videoId\": \"-A42gFYmqhI\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Elon Musk Just Revealed The Terrifying Truth Behind Antartica\",\n",
      "        \"description\": \"In the vast, frozen expanse of the southernmost continent lies a secret that has remained hidden for centuries. A secret so ...\",\n",
      "        \"videoId\": \"HpCTtJo9Gh0\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Mark Zuckerberg: Future of AI at Meta, Facebook, Instagram, and WhatsApp | Lex Fridman Podcast #383\",\n",
      "        \"description\": \"Mark Zuckerberg is CEO of Meta. SPONSORS: Please support this podcast by checking out our sponsors: - Numerai: ...\",\n",
      "        \"videoId\": \"Ff4fRgnuFgQ\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Mark Zuckerberg on the Quest Pro, metaverse, Elon&#39;s Twitter takeover and more\",\n",
      "        \"description\": \"Meta CEO Mark Zuckerberg joined The Verge's deputy editor Alex Heath for an in-depth conversation about the company's new ...\",\n",
      "        \"videoId\": \"gV50hpSKHFQ\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Elon Musk: Neuralink and the Future of Humanity | Lex Fridman Podcast #438\",\n",
      "        \"description\": \"Elon Musk is CEO of Neuralink, SpaceX, Tesla, xAI, and CTO of X. DJ Seo is COO & President of Neuralink. Matthew MacDougall ...\",\n",
      "        \"videoId\": \"Kbk9BiPhm7o\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"BMW CEO Collapses on Stage\",\n",
      "        \"description\": \"BMW CEO Harald Kr\\u00fcger collapsed during a news conference at the Frankfurt auto show on Tuesday. Mr. Kr\\u00fcger's condition ...\",\n",
      "        \"videoId\": \"E8FPTilI4D0\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Elon Musk Vs Zuckerberg - Lifestyle War 2024 Net Worth, Rich Life, Salary\",\n",
      "        \"description\": \"So who's the richer person? Zuckerberg or Elon Musk? Watch this video to find out! Elon Musk Vs Zuckerberg - Lifestyle War 2024 ...\",\n",
      "        \"videoId\": \"dqT_m9Wwrzw\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Mark Zuckerberg &amp; Dr. Priscilla Chan: Curing All Human Diseases &amp; the Future of Health &amp; Technology\",\n",
      "        \"description\": \"In this episode, my guests are Mark Zuckerberg, CEO of Meta (formerly Facebook, Inc.), and his wife, Dr. Priscilla Chan, M.D., ...\",\n",
      "        \"videoId\": \"1Wo6SqLNmLk\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Mark Zuckerberg: Meta, Facebook, Instagram, and the Metaverse | Lex Fridman Podcast #267\",\n",
      "        \"description\": \"Mark Zuckerberg is CEO of Meta, formerly Facebook. Please support this podcast by checking out our sponsors: - Paperspace: ...\",\n",
      "        \"videoId\": \"5zOHSysMmH0\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"Secret Sex Parties of the Mega-Rich | Informer\",\n",
      "        \"description\": \"A Front of House Manager reveals what working in a hotel for the super-rich is really like. From hiring out the whole hotel for a ...\",\n",
      "        \"videoId\": \"AXyzDxxQRSA\"\n",
      "    },\n",
      "    {\n",
      "        \"title\": \"WATCH LIVE: CEOs of Meta, TikTok, X and other social media companies testify in Senate hearing\",\n",
      "        \"description\": \"Stream your PBS favorites with the PBS app: https://to.pbs.org/2Jb8twG Find more from PBS NewsHour at ...\",\n",
      "        \"videoId\": \"VDmeGQcpRLQ\"\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "import json\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual API key\n",
    "api_key = 'AIzaSyBpSTBKNkwOs42snYcRm38fDv5N-mU0M1Y'\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "def search_videos(query):\n",
    "    # Call the search.list method to retrieve results matching the specified query term.\n",
    "    response = youtube.search().list(\n",
    "        q=query,\n",
    "        part='id,snippet',\n",
    "        maxResults=20,\n",
    "        type='video'\n",
    "    ).execute()\n",
    "\n",
    "    videos = []\n",
    "    for item in response.get('items', []):\n",
    "        # Add each result to the list, and then display the results.\n",
    "        videos.append({\n",
    "            'title': item['snippet']['title'],\n",
    "            'description': item['snippet']['description'],\n",
    "            'videoId': item['id']['videoId']\n",
    "        })\n",
    "    \n",
    "    return videos\n",
    "\n",
    "# Search for videos about Elon Musk vs. Mark Zuckerberg\n",
    "query = 'Influence and Network Dynamics: Elon Musk vs. Mark Zuckerberg'\n",
    "videos = search_videos(query)\n",
    "\n",
    "# Print the video details\n",
    "print(json.dumps(videos, indent=4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b64d80e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to tesla_under_musk.json\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import json\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual API key\n",
    "api_key = 'AIzaSyBpSTBKNkwOs42snYcRm38fDv5N-mU0M1Y'\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "def search_videos(query):\n",
    "    try:\n",
    "        # Search for videos matching the query\n",
    "        search_response = youtube.search().list(\n",
    "            q=query,\n",
    "            part='id,snippet',\n",
    "            maxResults=50,\n",
    "            type='video'\n",
    "        ).execute()\n",
    "\n",
    "        videos = []\n",
    "\n",
    "        for search_result in search_response.get('items', []):\n",
    "            video_id = search_result['id']['videoId']\n",
    "            video_response = youtube.videos().list(\n",
    "                part='snippet,statistics',\n",
    "                id=video_id\n",
    "            ).execute()\n",
    "\n",
    "            for video in video_response.get('items', []):\n",
    "                # Initialize comments list\n",
    "                comments = []\n",
    "\n",
    "                try:\n",
    "                    # Attempt to fetch top 5 comments\n",
    "                    comments_response = youtube.commentThreads().list(\n",
    "                        part='snippet',\n",
    "                        videoId=video_id,\n",
    "                        maxResults=5,  # Fetch only top 5 comments\n",
    "                        textFormat='plainText'\n",
    "                    ).execute()\n",
    "\n",
    "                    for comment in comments_response.get('items', []):\n",
    "                        comments.append(comment['snippet']['topLevelComment']['snippet']['textDisplay'])\n",
    "\n",
    "                except HttpError as e:\n",
    "                    if e.resp.status == 403:\n",
    "                        print(f\"Comments are disabled for video ID {video_id}. Skipping comments.\")\n",
    "                    else:\n",
    "                        raise  # Re-raise the exception if it's not a known error\n",
    "\n",
    "                # Append video details\n",
    "                videos.append({\n",
    "                    'title': video['snippet']['title'],\n",
    "                    'author': video['snippet']['channelTitle'],\n",
    "                    'video_id': video_id,\n",
    "                    'likes': video['statistics'].get('likeCount', '0'),\n",
    "                    'description': video['snippet']['description'],\n",
    "                    'top_5_comments': comments\n",
    "                })\n",
    "\n",
    "        return videos\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f\"An HTTP error {e.resp.status} occurred:\\n{e.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example query\n",
    "query = 'Tesla Market under Elon Musk'\n",
    "videos = search_videos(query)\n",
    "\n",
    "# Save the video details to a JSON file\n",
    "with open('tesla_under_musk.json', 'w') as json_file:\n",
    "    json.dump(videos, json_file, indent=4)\n",
    "\n",
    "print(\"Data saved to tesla_under_musk.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67d2abc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments are disabled for video ID PGoLsbkI8WU. Skipping comments.\n",
      "Data saved to twitter_under_musk.json\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import json\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual API key\n",
    "api_key = 'AIzaSyBpSTBKNkwOs42snYcRm38fDv5N-mU0M1Y'  # Make sure to replace with your actual API key\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "def search_videos(query):\n",
    "    try:\n",
    "        # Search for videos matching the query\n",
    "        search_response = youtube.search().list(\n",
    "            q=query,\n",
    "            part='id,snippet',\n",
    "            maxResults=50,\n",
    "            type='video'\n",
    "        ).execute()\n",
    "\n",
    "        videos = []\n",
    "\n",
    "        for search_result in search_response.get('items', []):\n",
    "            video_id = search_result['id']['videoId']\n",
    "            video_response = youtube.videos().list(\n",
    "                part='snippet,statistics',\n",
    "                id=video_id\n",
    "            ).execute()\n",
    "\n",
    "            for video in video_response.get('items', []):\n",
    "                # Initialize comments list\n",
    "                comments = []\n",
    "\n",
    "                try:\n",
    "                    # Attempt to fetch top 5 comments\n",
    "                    comments_response = youtube.commentThreads().list(\n",
    "                        part='snippet',\n",
    "                        videoId=video_id,\n",
    "                        maxResults=5,  # Fetch only top 5 comments\n",
    "                        textFormat='plainText'\n",
    "                    ).execute()\n",
    "\n",
    "                    for comment in comments_response.get('items', []):\n",
    "                        comments.append(comment['snippet']['topLevelComment']['snippet']['textDisplay'])\n",
    "\n",
    "                except HttpError as e:\n",
    "                    if e.resp.status == 403:\n",
    "                        print(f\"Comments are disabled for video ID {video_id}. Skipping comments.\")\n",
    "                    else:\n",
    "                        raise  # Re-raise the exception if it's not a known error\n",
    "\n",
    "                # Append video details\n",
    "                videos.append({\n",
    "                    'title': video['snippet']['title'],\n",
    "                    'author': video['snippet']['channelTitle'],\n",
    "                    'video_id': video_id,\n",
    "                    'likes': video['statistics'].get('likeCount', '0'),\n",
    "                    'description': video['snippet']['description'],\n",
    "                    'top_5_comments': comments\n",
    "                })\n",
    "\n",
    "        return videos\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f\"An HTTP error {e.resp.status} occurred:\\n{e.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example query\n",
    "query = 'Twitter market under Elon Musk'\n",
    "videos = search_videos(query)\n",
    "\n",
    "# Save the video details to a JSON file\n",
    "with open('twitter_under_musk.json', 'w') as json_file:\n",
    "    json.dump(videos, json_file, indent=4)\n",
    "\n",
    "print(\"Data saved to twitter_under_musk.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08d8feb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos retrieved: 122\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open('tesla_under_musk_100.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Count the number of video entries\n",
    "video_count = len(data)\n",
    "\n",
    "print(f\"Number of videos retrieved: {video_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "415d02e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos retrieved: 148\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load the JSON data from the file\n",
    "with open('twitter_under_musk_100.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Count the number of video entries\n",
    "video_count = len(data)\n",
    "\n",
    "print(f\"Number of videos retrieved: {video_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a3dc0839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments are disabled for video ID B3ROCh7goXM. Skipping comments.\n",
      "Comments are disabled for video ID dKgFLdWUsNY. Skipping comments.\n",
      "Comments are disabled for video ID OKhYcB-9x28. Skipping comments.\n",
      "Data saved to tesla_under_musk_100.json\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import json\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual API key\n",
    "api_key = 'AIzaSyBpSTBKNkwOs42snYcRm38fDv5N-mU0M1Y'\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "def search_videos(query):\n",
    "    try:\n",
    "        videos = []\n",
    "        video_ids = set()  # To track unique video IDs\n",
    "        next_page_token = None\n",
    "        total_results = 0\n",
    "\n",
    "        while total_results < 100:\n",
    "            # Search for videos matching the query\n",
    "            search_response = youtube.search().list(\n",
    "                q=query,\n",
    "                part='id,snippet',\n",
    "                maxResults=50,  # Adjust maxResults as needed\n",
    "                pageToken=next_page_token,\n",
    "                type='video'\n",
    "            ).execute()\n",
    "\n",
    "            for search_result in search_response.get('items', []):\n",
    "                video_id = search_result['id']['videoId']\n",
    "                if video_id not in video_ids:\n",
    "                    video_ids.add(video_id)\n",
    "                    video_response = youtube.videos().list(\n",
    "                        part='snippet,statistics',\n",
    "                        id=video_id\n",
    "                    ).execute()\n",
    "\n",
    "                    for video in video_response.get('items', []):\n",
    "                        # Initialize comments list\n",
    "                        comments = []\n",
    "\n",
    "                        try:\n",
    "                            # Attempt to fetch top 5 comments\n",
    "                            comments_response = youtube.commentThreads().list(\n",
    "                                part='snippet',\n",
    "                                videoId=video_id,\n",
    "                                maxResults=5,  # Fetch only top 5 comments\n",
    "                                textFormat='plainText'\n",
    "                            ).execute()\n",
    "\n",
    "                            for comment in comments_response.get('items', []):\n",
    "                                comments.append(comment['snippet']['topLevelComment']['snippet']['textDisplay'])\n",
    "\n",
    "                        except HttpError as e:\n",
    "                            if e.resp.status == 403:\n",
    "                                print(f\"Comments are disabled for video ID {video_id}. Skipping comments.\")\n",
    "                            else:\n",
    "                                raise  # Re-raise the exception if it's not a known error\n",
    "\n",
    "                        # Append video details\n",
    "                        videos.append({\n",
    "                            'title': video['snippet']['title'],\n",
    "                            'author': video['snippet']['channelTitle'],\n",
    "                            'video_id': video_id,\n",
    "                            'likes': video['statistics'].get('likeCount', '0'),\n",
    "                            'description': video['snippet']['description'],\n",
    "                            'top_5_comments': comments\n",
    "                        })\n",
    "\n",
    "                        total_results += 1\n",
    "                        if total_results >= 100:\n",
    "                            break\n",
    "\n",
    "            next_page_token = search_response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break  # Exit loop if no more results are available\n",
    "\n",
    "        return videos\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f\"An HTTP error {e.resp.status} occurred:\\n{e.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example query\n",
    "query = 'Tesla Market under Elon Musk'\n",
    "videos = search_videos(query)\n",
    "\n",
    "# Save the video details to a JSON file\n",
    "with open('tesla_under_musk_100.json', 'w') as json_file:\n",
    "    json.dump(videos, json_file, indent=4)\n",
    "\n",
    "print(\"Data saved to tesla_under_musk_100.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a8a58de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comments are disabled for video ID PGoLsbkI8WU. Skipping comments.\n",
      "Comments are disabled for video ID LfDor7P-520. Skipping comments.\n",
      "Comments are disabled for video ID gUFpbhAsc5g. Skipping comments.\n",
      "Data saved to twitter_under_musk_100.json\n"
     ]
    }
   ],
   "source": [
    "from googleapiclient.discovery import build\n",
    "from googleapiclient.errors import HttpError\n",
    "import json\n",
    "\n",
    "# Replace 'YOUR_API_KEY' with your actual API key\n",
    "api_key = 'AIzaSyBpSTBKNkwOs42snYcRm38fDv5N-mU0M1Y'\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)\n",
    "\n",
    "def search_videos(query):\n",
    "    try:\n",
    "        videos = []\n",
    "        video_ids = set()  # To track unique video IDs\n",
    "        next_page_token = None\n",
    "        total_results = 0\n",
    "\n",
    "        while total_results < 100:\n",
    "            # Search for videos matching the query\n",
    "            search_response = youtube.search().list(\n",
    "                q=query,\n",
    "                part='id,snippet',\n",
    "                maxResults=50,  # Adjust maxResults as needed\n",
    "                pageToken=next_page_token,\n",
    "                type='video'\n",
    "            ).execute()\n",
    "\n",
    "            for search_result in search_response.get('items', []):\n",
    "                video_id = search_result['id']['videoId']\n",
    "                if video_id not in video_ids:\n",
    "                    video_ids.add(video_id)\n",
    "                    video_response = youtube.videos().list(\n",
    "                        part='snippet,statistics',\n",
    "                        id=video_id\n",
    "                    ).execute()\n",
    "\n",
    "                    for video in video_response.get('items', []):\n",
    "                        # Initialize comments list\n",
    "                        comments = []\n",
    "\n",
    "                        try:\n",
    "                            # Attempt to fetch top 5 comments\n",
    "                            comments_response = youtube.commentThreads().list(\n",
    "                                part='snippet',\n",
    "                                videoId=video_id,\n",
    "                                maxResults=5,  # Fetch only top 5 comments\n",
    "                                textFormat='plainText'\n",
    "                            ).execute()\n",
    "\n",
    "                            for comment in comments_response.get('items', []):\n",
    "                                comments.append(comment['snippet']['topLevelComment']['snippet']['textDisplay'])\n",
    "\n",
    "                        except HttpError as e:\n",
    "                            if e.resp.status == 403:\n",
    "                                print(f\"Comments are disabled for video ID {video_id}. Skipping comments.\")\n",
    "                            else:\n",
    "                                raise  # Re-raise the exception if it's not a known error\n",
    "\n",
    "                        # Append video details\n",
    "                        videos.append({\n",
    "                            'title': video['snippet']['title'],\n",
    "                            'author': video['snippet']['channelTitle'],\n",
    "                            'video_id': video_id,\n",
    "                            'likes': video['statistics'].get('likeCount', '0'),\n",
    "                            'description': video['snippet']['description'],\n",
    "                            'top_5_comments': comments\n",
    "                        })\n",
    "\n",
    "                        total_results += 1\n",
    "                        if total_results >= 100:\n",
    "                            break\n",
    "\n",
    "            next_page_token = search_response.get('nextPageToken')\n",
    "            if not next_page_token:\n",
    "                break  # Exit loop if no more results are available\n",
    "\n",
    "        return videos\n",
    "\n",
    "    except HttpError as e:\n",
    "        print(f\"An HTTP error {e.resp.status} occurred:\\n{e.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "\n",
    "# Example query\n",
    "query = 'Twitter market under Elon Musk'\n",
    "videos = search_videos(query)\n",
    "\n",
    "# Save the video details to a JSON file\n",
    "with open('twitter_under_musk_100.json', 'w') as json_file:\n",
    "    json.dump(videos, json_file, indent=4)\n",
    "\n",
    "print(\"Data saved to twitter_under_musk_100.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272291be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b68854f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bee5ba9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee37cbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
